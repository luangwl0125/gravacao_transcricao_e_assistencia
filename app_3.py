import sys, audioop
sys.modules['pyaudioop'] = audioop

from pathlib import Path
from datetime import datetime
import time
import queue

import tempfile
import os
import streamlit as st
from streamlit_webrtc import WebRtcMode, webrtc_streamer

import openai
import pydub
from moviepy.video.io.VideoFileClip import VideoFileClip
from dotenv import load_dotenv, find_dotenv
from openai import RateLimitError

_ = load_dotenv(find_dotenv())

# DiretÃ³rio temporÃ¡rio
PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)

# DiretÃ³rio de transcriÃ§Ãµes
PASTA_TRANSCRICOES = Path(__file__).parent / 'TRANSCRICOES'
PASTA_TRANSCRICOES.mkdir(exist_ok=True)

# Arquivos temporÃ¡rios
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.wav'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'
ARQUIVO_MIC_TEMP = PASTA_TEMP / 'mic.wav'

# Cliente OpenAI
client = openai.OpenAI()

# Modelo Whisper local para fallback
local_model = None

def get_local_whisper():
    global local_model
    if local_model is None:
        import whisper
        local_model = whisper.load_model("base")
    return local_model

# ConfiguraÃ§Ãµes de retry
MAX_RETRIES = 3
RETRY_DELAY = 2  # segundos

def handle_openai_error(func):
    def wrapper(*args, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return func(*args, **kwargs)
            except RateLimitError as e:
                if attempt == MAX_RETRIES - 1:
                    st.warning("OpenAI API rate limit atingido. Usando serviÃ§o local de fallback.")
                    return use_fallback_service(*args, **kwargs)
                else:
                    time.sleep(RETRY_DELAY * (attempt + 1))
            except Exception as e:
                st.error(f"Erro ao processar: {str(e)}")
                return None
    return wrapper

def use_fallback_service(caminho_audio=None, prompt=None, texto=None):
    try:
        if caminho_audio:
            model = get_local_whisper()
            result = model.transcribe(caminho_audio, language="pt")
            return result["text"], "AnÃ¡lise nÃ£o disponÃ­vel (usando serviÃ§o local)"
        elif texto:
            return texto, "AnÃ¡lise nÃ£o disponÃ­vel (usando serviÃ§o local)"
    except Exception as e:
        st.error(f"Erro no serviÃ§o de fallback: {str(e)}")
        return "", ""

# Prompt para o ChatGPT
PROMPT_PSICOLOGICO = ''' 
VocÃª Ã© um PsicÃ³logo/NeuropsicÃ³logo Assistente com mais de 30 anos de experiÃªncia no Brasil, atuando diretamente como suporte tÃ©cnico de LUAN GAMA WANDERLEY LEITE (CRP-15/3328), PsicÃ³logo e Assessor TÃ©cnico da Defensoria PÃºblica do Estado de Alagoas (Mat. 9864616-8).

Sua tarefa Ã© analisar as informaÃ§Ãµes registradas a seguir, delimitadas por #### DADOS ####, e produzir uma **estrutura de avaliaÃ§Ã£o psicolÃ³gica inicial**, de acordo com os parÃ¢metros Ã©tico-profissionais, com base cientÃ­fica e 100% conforme as resoluÃ§Ãµes do CFP.

Siga estritamente as seguintes seÃ§Ãµes e orientaÃ§Ãµes:

ğŸ” **1. IDENTIFICAÃ‡ÃƒO DA DEMANDA**  
- Especifique a origem da demanda: espontÃ¢nea, judicial, institucional ou encaminhamento.  
- Avalie a urgÃªncia e a natureza principal da demanda (psicolÃ³gica, psiquiÃ¡trica, social, jurÃ­dica).  

ğŸ“‹ **2. REGISTRO E DOCUMENTAÃ‡ÃƒO**  
- Realize anamnese com dados sociodemogrÃ¡ficos, histÃ³ria clÃ­nica, familiar, social, educacional e laboral.  
- Registre de forma Ã©tica e sigilosa, conforme as ResoluÃ§Ãµes CFP nÂº 01/2009 e nÂº 06/2019.  
- Utilize instrumentos estruturados e entrevistas clÃ­nicas conforme a ResoluÃ§Ã£o CFP nÂº 31/2022.  

ğŸ§  **3. OBSERVAÃ‡ÃƒO PSICOLÃ“GICA E IMPRESSÃ•ES CLÃNICAS INICIAIS**  
- Descreva o estado mental, o comportamento observado e o modo de comunicaÃ§Ã£o do assistido.  
- Registre indicadores de sofrimento psÃ­quico, risco psicossocial, sinais de violÃªncia ou ideaÃ§Ã£o suicida.  

ğŸ§¾ **4. PLANO INICIAL DE AÃ‡ÃƒO**  
- Indique se haverÃ¡ continuidade do acompanhamento na DPE ou necessidade de encaminhamento (CAPS, CRAS, UBS etc.).  
- Avalie a necessidade de elaboraÃ§Ã£o de documentos (relatÃ³rio, laudo, parecer) ou aprofundamento diagnÃ³stico.  

ğŸ§‘â€âš–ï¸ **5. CONTEXTO JURÃDICO E ARTICULAÃ‡ÃƒO INTERSETORIAL**  
- Verifique a existÃªncia de vÃ­nculo com processos jurÃ­dicos e, se aplicÃ¡vel, a articulaÃ§Ã£o com defensores(as).  
- Projete a produÃ§Ã£o de documentos que possam subsidiar decisÃµes judiciais.  

ğŸ¤ **6. CONSENTIMENTO E ORIENTAÃ‡Ã•ES Ã‰TICAS**  
- Confirme que foram explicadas as regras de sigilo, os limites da atuaÃ§Ã£o na DPE e os usos das informaÃ§Ãµes.  
- Verifique e registre a obtenÃ§Ã£o de Termo de Consentimento Informado, se aplicÃ¡vel.  

ğŸ“Œ **7. HIPÃ“TESES DIAGNÃ“STICAS INICIAIS E ENCAMINHAMENTOS**  
- Apresente hipÃ³teses diagnÃ³sticas preliminares com base nos dados e instrumentos disponÃ­veis.  
- Estruture um Termo de Encaminhamento interno ou externo, se pertinente.

**Diretrizes complementares:**
- Utilize linguagem tÃ©cnica e clara, evitando inferÃªncias nÃ£o fundamentadas.  
- Mantenha fidelidade aos dados. Caso algo nÃ£o tenha sido informado, sinalize como "nÃ£o identificado".  
- Fundamente suas observaÃ§Ãµes na literatura e nas normas do CFP.

O conteÃºdo a ser analisado estÃ¡ entre os delimitadores:

#### DADOS ####
{}
#### DADOS ####
'''

PROMPT_JURIDICO = ''' 
VocÃª Ã© um Defensor PÃºblico Supervisor e sua tarefa Ã© analisar tecnicamente a transcriÃ§Ã£o de um atendimento jurÃ­dico prestado no NÃºcleo de Atendimento a Idosos da Defensoria PÃºblica do Estado de Alagoas.

Sua anÃ¡lise servirÃ¡ de base para orientaÃ§Ã£o e formaÃ§Ã£o dos estagiÃ¡rios envolvidos. Utilize linguagem tÃ©cnica e formal, rigorosamente jurÃ­dica, e estruture a resposta conforme os tÃ³picos indicados abaixo.

Diretrizes:

1. Evite inferÃªncias nÃ£o sustentadas nos fatos relatados. Se houver lacunas, registre como "nÃ£o informado" ou "nÃ£o identificado".
2. Respeite o sigilo e a Ã©tica profissional; nÃ£o inclua juÃ­zos de valor ou suposiÃ§Ãµes pessoais.
3. Utilize o conteÃºdo delimitado por #### TRANSCRIÃ‡ÃƒO #### como Ãºnica fonte de anÃ¡lise.

**SeÃ§Ãµes ObrigatÃ³rias (tÃ­tulos em maiÃºsculo):**

- DADOS DO ATENDIMENTO  
- QUALIFICAÃ‡ÃƒO E CONTEXTO DO ASSISTIDO  
- PROBLEMA JURÃDICO APRESENTADO  
- ELEMENTOS DE FATO RELEVANTES  
- ELEMENTOS DE DIREITO IDENTIFICADOS  
- AÃ‡Ã•ES REALIZADAS NO ATENDIMENTO  
- ANÃLISE CRÃTICA DO PROCEDIMENTO  
- ORIENTAÃ‡Ã•ES PARA O ESTAGIÃRIO  

O conteÃºdo da transcriÃ§Ã£o a ser analisado estÃ¡ delimitado entre #### TRANSCRIÃ‡ÃƒO ####.

#### TRANSCRIÃ‡ÃƒO ####
{}
#### TRANSCRIÃ‡ÃƒO ####
'''

PROMPT_SERVICO_SOCIAL = '''
VocÃª Ã© um Assistente de ServiÃ§o Social com sÃ³lida experiÃªncia em atuaÃ§Ã£o na Defensoria PÃºblica, especializado em demandas sociais de pessoas idosas. Sua tarefa Ã© analisar as informaÃ§Ãµes a seguir, delimitadas por #### DADOS ####, e produzir uma **estrutura de avaliaÃ§Ã£o social inicial**, de acordo com as normas Ã©ticoâ€profissionais do ServiÃ§o Social (CFESS/CFP) e com base em evidÃªncias. Siga rigorosamente as seÃ§Ãµes abaixo:

1. CONTEXTO E HISTÃ“RICO:
   - Identifique origem da demanda: espontÃ¢nea, judicial, institucional ou encaminhamento.
   - Registre informaÃ§Ãµes sociodemogrÃ¡ficas, composiÃ§Ã£o familiar, rede de apoio, condiÃ§Ãµes de moradia e renda.
   - Contextualize aspectos culturais e ambientais relevantes Ã  situaÃ§Ã£o do assistido.

2. DIAGNÃ“STICO SOCIAL:
   - Avalie fatores de risco social: vulnerabilidade, violÃªncia, abandono, carÃªncia de recursos.
   - Verifique acesso a polÃ­ticas pÃºblicas (CRAS, CREAS, BenefÃ­cio de PrestaÃ§Ã£o Continuada, HabitaÃ§Ã£o Popular etc.).
   - Identifique indicadores de fragilidade: saÃºde precÃ¡ria, isolamento, dependÃªncia financeira.

3. RECURSOS E REDES DE APOIO:
   - Liste serviÃ§os e programas sociais disponÃ­veis e possÃ­veis encaminhamentos.
   - Avalie a presenÃ§a de cuidadores formais/informais e a qualidade do suporte familiar.
   - AnÃ¡lise da viabilidade de programas de proteÃ§Ã£o ao idoso ou rede de assistÃªncia.

4. PLANO DE INTERVENÃ‡ÃƒO INICIAL:
   - Defina aÃ§Ãµes imediatas e de mÃ©dio prazo: solicitaÃ§Ã£o de benefÃ­cios, inclusÃ£o em programas de assistÃªncia, articulaÃ§Ã£o com Ã³rgÃ£os municipais/estaduais.
   - Sugira inclusÃ£o em rede de serviÃ§os (SaÃºde, AssistÃªncia Social, EducaÃ§Ã£o, Direitos Humanos).
   - Preveja acompanhamento continuado e frequÃªncia de visitas domiciliares (se necessÃ¡rio).

5. ARTICULAÃ‡ÃƒO INTERSETORIAL:
   - Verifique vÃ­nculo com processos judiciais e atuaÃ§Ã£o conjunta com Defensoria PÃºblica.
   - Projete relatÃ³rios tÃ©cnicos ou pareceres para subsidiar decisÃµes judiciais e sociais.
   - Indique possÃ­veis parcerias com organizaÃ§Ãµes nÃ£o governamentais e conselhos de direitos do idoso.

6. Ã‰TICA E DIRETRIZES PROFISSIONAIS:
   - Confirme cumprimento de normativas do CFESS e princÃ­pios do ServiÃ§o Social: sigilo, autonomia, respeito Ã  dignidade.
   - Registre obtenÃ§Ã£o de Termo de Consentimento Informado, se aplicÃ¡vel.
   - Ressalte a importÃ¢ncia da escuta qualificada e do protagonismo do assistido.

7. ENCAMINHAMENTOS E RECOMENDAÃ‡Ã•ES:
   - Apresente encaminhamentos imediatos (CRAS, CREAS, CAPS, UBS, CAPS-Idoso, CUCA etc.).
   - Sugira estratÃ©gias de fortalecimento de rede social: grupos de convivÃªncia, Centro Dia do Idoso.
   - Estruture modelo de RelatÃ³rio Social ou Parecer Social para a Defensoria PÃºblica.

#### DADOS ####
{}
#### DADOS ####
'''

PROMPTS = {
    "PsicolÃ³gico": PROMPT_PSICOLOGICO,
    "JurÃ­dico": PROMPT_JURIDICO,
    "ServiÃ§o Social": PROMPT_SERVICO_SOCIAL
}

@handle_openai_error
def processa_transcricao_chatgpt(texto: str) -> str:
    resposta = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": PROMPT_PSICOLOGICO.format(texto)}
        ]
    )
    return resposta.choices[0].message.content

def converter_para_wav(caminho_entrada: str) -> str:
    audio = pydub.AudioSegment.from_file(caminho_entrada)
    fd, caminho_wav = tempfile.mkstemp(suffix=".wav", prefix="audio_")
    os.close(fd)
    audio.export(caminho_wav, format="wav")
    return caminho_wav

@handle_openai_error
def transcreve_audio(caminho_audio: str, prompt: str) -> tuple[str, str]:
    with open(caminho_audio, 'rb') as arquivo:
        try:
            resp = client.audio.transcriptions.create(
                model='whisper-1',
                language='pt',
                response_format='text',
                file=arquivo,
                prompt=prompt,
            )
            analise = processa_transcricao_chatgpt(resp)
            return resp, analise
        except Exception as e:
            st.warning(f"Erro na API OpenAI: {str(e)}. Usando serviÃ§o local.")
            return use_fallback_service(caminho_audio, prompt)

if 'transcricao_mic' not in st.session_state:
    st.session_state['transcricao_mic'] = ''
if 'analise_mic' not in st.session_state:
    st.session_state['analise_mic'] = ''
if 'gravando_audio' not in st.session_state:
    st.session_state['gravando_audio'] = False
if 'audio_completo' not in st.session_state:
    st.session_state['audio_completo'] = pydub.AudioSegment.empty()

@st.cache_data
def get_ice_servers():
    return [{'urls': ['stun:stun.l.google.com:19302']}]

def adiciona_chunck_de_audio(frames, chunk_audio):
    for frame in frames:
        seg = pydub.AudioSegment(
            data=frame.to_ndarray().tobytes(),
            sample_width=frame.format.bytes,
            frame_rate=frame.sample_rate,
            channels=len(frame.layout.channels)
        )
        chunk_audio += seg
    return chunk_audio

def salva_transcricao(texto: str, analise: str, origem: str = ""):
    agora = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    prefixo = f"{agora}_{origem}" if origem else agora
    with open(PASTA_TRANSCRICOES / f"{prefixo}_transcricao.txt", 'w', encoding='utf-8') as f:
        f.write(texto)
    with open(PASTA_TRANSCRICOES / f"{prefixo}_analise.txt", 'w', encoding='utf-8') as f:
        f.write(analise)
    return

def transcreve_tab_mic():
    tipo_atendimento = st.radio('Tipo de Atendimento:', list(PROMPTS.keys()), horizontal=True)
    prompt_mic = PROMPTS[tipo_atendimento]
    st.text_area("Prompt Selecionado:", prompt_mic[:800] + '...', height=300)

    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button('ğŸ”´ Gravar Ãudio' if not st.session_state['gravando_audio'] else 'â¹ï¸ Parar GravaÃ§Ã£o'):
            st.session_state['gravando_audio'] = not st.session_state['gravando_audio']
            if not st.session_state['gravando_audio'] and len(st.session_state['audio_completo']) > 0:
                st.session_state['audio_completo'].export(
                    PASTA_TRANSCRICOES / f"audio_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.wav",
                    format='wav'
                )
                st.session_state['audio_completo'] = pydub.AudioSegment.empty()

    ctx = webrtc_streamer(
        key='mic', mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={'video': False, 'audio': True},
        rtc_configuration={"iceServers": get_ice_servers()}
    )

    if not ctx.state.playing:
        if st.session_state['gravando_audio']:
            st.session_state['gravando_audio'] = False
            if len(st.session_state['audio_completo']) > 0:
                st.session_state['audio_completo'].export(
                    PASTA_TRANSCRICOES / f"audio_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.wav",
                    format='wav'
                )
                st.session_state['audio_completo'] = pydub.AudioSegment.empty()

        if st.session_state['transcricao_mic']:
            if not st.session_state['analise_mic']:
                st.write("Gerando anÃ¡lise...")
                st.session_state['analise_mic'] = processa_transcricao_chatgpt(st.session_state['transcricao_mic'])
            st.write("**TranscriÃ§Ã£o:**")
            st.write(st.session_state['transcricao_mic'])
            st.write("**AnÃ¡lise:**")
            st.write(st.session_state['analise_mic'])
            salva_transcricao(
                st.session_state['transcricao_mic'],
                st.session_state['analise_mic'],
                'microfone'
            )
        return

    status_col1, status_col2 = st.columns(2)
    with status_col1:
        st.markdown('**ğŸ™ï¸ Transcrevendo...**')
    with status_col2:
        if st.session_state['gravando_audio']:
            st.markdown('**ğŸ”´ Gravando Ã¡udio...**')

    placeholder = st.empty()
    chunk_audio = pydub.AudioSegment.empty()
    ultimo = time.time()
    st.session_state['transcricao_mic'] = ''
    st.session_state['analise_mic'] = ''

    while ctx.audio_receiver:
        try:
            frames = ctx.audio_receiver.get_frames(timeout=1)
        except queue.Empty:
            time.sleep(0.1)
            continue

        chunk_atual = pydub.AudioSegment.empty()
        chunk_atual = adiciona_chunck_de_audio(frames, chunk_atual)
        chunk_audio += chunk_atual

        if st.session_state['gravando_audio']:
            st.session_state['audio_completo'] += chunk_atual

        agora = time.time()
        if len(chunk_audio) > 0 and agora - ultimo > 10:
            ultimo = agora
            chunk_audio.export(ARQUIVO_MIC_TEMP, format='wav')
            texto, _ = transcreve_audio(str(ARQUIVO_MIC_TEMP), prompt_mic)
            st.session_state['transcricao_mic'] += texto
            placeholder.write(st.session_state['transcricao_mic'])
            chunk_audio = pydub.AudioSegment.empty()

def main():
    st.header('ğŸ™ï¸ Assistente de OrganizaÃ§Ã£o ğŸ™ï¸')
    st.markdown('GravaÃ§Ã£o, TranscriÃ§Ã£o e OrganizaÃ§Ã£o.')
    st.markdown('ReuniÃµes, Palestras, Atendimentos e Outros.')
    abas = st.tabs(['Microfone', 'VÃ­deo', 'Ãudio', 'Texto'])
    with abas[0]:
        transcreve_tab_mic()

if __name__ == '__main__':
    main()
