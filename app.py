import sys, audioop
sys.modules['pyaudioop'] = audioop

from pathlib import Path
from datetime import datetime
import time
import queue

import tempfile
import os
import streamlit as st
from streamlit_webrtc import WebRtcMode, webrtc_streamer

import openai
import pydub
from moviepy.video.io.VideoFileClip import VideoFileClip
from dotenv import load_dotenv, find_dotenv
from openai import RateLimitError

_ = load_dotenv(find_dotenv())

# Diret√≥rio tempor√°rio
PASTA_TEMP = Path(__file__).parent / 'temp'
PASTA_TEMP.mkdir(exist_ok=True)

# Diret√≥rio de transcri√ß√µes
PASTA_TRANSCRICOES = Path(__file__).parent / 'TRANSCRICOES'
PASTA_TRANSCRICOES.mkdir(exist_ok=True)

# Arquivos tempor√°rios
ARQUIVO_AUDIO_TEMP = PASTA_TEMP / 'audio.wav'
ARQUIVO_VIDEO_TEMP = PASTA_TEMP / 'video.mp4'
ARQUIVO_MIC_TEMP = PASTA_TEMP / 'mic.wav'

# Cliente OpenAI
client = openai.OpenAI()

# Modelo Whisper local para fallback
local_model = None

def get_local_whisper():
    global local_model
    if local_model is None:
        local_model = whisper.load_model("base")
    return local_model

# Configura√ß√µes de retry
MAX_RETRIES = 3
RETRY_DELAY = 2  # segundos

def handle_openai_error(func):
    def wrapper(*args, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return func(*args, **kwargs)
            except RateLimitError as e:
                if attempt == MAX_RETRIES - 1:  # Se for a √∫ltima tentativa
                    st.warning("OpenAI API rate limit atingido. Usando servi√ßo local de fallback.")
                    return use_fallback_service(*args, **kwargs)
                else:
                    time.sleep(RETRY_DELAY * (attempt + 1))  # Espera exponencial
            except Exception as e:
                st.error(f"Erro ao processar: {str(e)}")
                return None
    return wrapper

def use_fallback_service(caminho_audio=None, prompt=None, texto=None):
    """Servi√ßo de fallback usando Whisper local"""
    try:
        if caminho_audio:  # Para transcri√ß√£o
            model = get_local_whisper()
            result = model.transcribe(caminho_audio, language="pt")
            return result["text"], "An√°lise n√£o dispon√≠vel (usando servi√ßo local)"
        elif texto:  # Para an√°lise
            return texto, "An√°lise n√£o dispon√≠vel (usando servi√ßo local)"
    except Exception as e:
        st.error(f"Erro no servi√ßo de fallback: {str(e)}")
        return "", ""

PROMPT_JURIDICO = ''' 
Voc√™ √© um Defensor P√∫blico Supervisor, especialista em Direito P√∫blico, com √™nfase em Direitos Humanos, Direito da Pessoa Idosa e Direito Previdenci√°rio. Sua fun√ß√£o √© analisar tecnicamente a transcri√ß√£o de um atendimento jur√≠dico prestado no N√∫cleo de Atendimento a Idosos da Defensoria P√∫blica do Estado de Alagoas.

Sua an√°lise servir√° de base para:
- Orientar estagi√°rios de Direito;
- Elaborar documentos jur√≠dicos e administrativos;
- Produzir minutas de peti√ß√µes iniciais, manifesta√ß√µes, of√≠cios, notifica√ß√µes, requerimentos e recursos, conforme aplic√°vel ao caso concreto.

Utilize linguagem jur√≠dica formal, clara e objetiva, com base nas normas vigentes e boa t√©cnica argumentativa.

**Fundamenta√ß√£o jur√≠dica obrigat√≥ria (a aplicar conforme o caso):**

üìò **Constitui√ß√£o Federal de 1988**  
- Art. 1¬∫, III; Art. 3¬∫, IV; Art. 5¬∫; Art. 6¬∫; Art. 230

üìï **Estatuto da Pessoa Idosa (Lei n¬∫ 10.741/2003)**  
- Direitos fundamentais (arts. 2¬∫ a 21)  
- Previd√™ncia, Assist√™ncia, Sa√∫de, Trabalho e Justi√ßa (arts. 22 a 46)  
- Penaliza√ß√µes (arts. 49 a 108)

üìó **Lei Org√¢nica da Assist√™ncia Social (Lei n¬∫ 8.742/1993)**  
üìò **Lei n¬∫ 8.213/1991 ‚Äì Benef√≠cios Previdenci√°rios**  
üìò **Lei n¬∫ 13.146/2015 ‚Äì Estatuto da Pessoa com Defici√™ncia (quando aplic√°vel)**  
üìò **C√≥digo Civil** (Alimentos, Interdi√ß√£o, Curatela)  
üìò **C√≥digo de Processo Civil** (Tutela Provis√≥ria, Interdi√ß√£o, Alimentos)

**Tipos de documentos/peti√ß√µes que voc√™ pode elaborar a partir da an√°lise:**

- Peti√ß√£o Inicial (Alimentos, Curatela, Interdi√ß√£o, Benef√≠cio Assistencial, Tutela Antecipada)  
- Requerimento administrativo √† rede p√∫blica (CRAS, CAPS, UBS, INSS etc.)  
- Notifica√ß√£o Extrajudicial  
- Of√≠cio Institucional para encaminhamentos ou articula√ß√µes intersetoriais  
- Declara√ß√£o ou termo de comparecimento  
- Requisi√ß√£o de documentos ou exames  
- Minuta de manifesta√ß√£o, r√©plica ou apela√ß√£o conforme o andamento processual

**Diretrizes obrigat√≥rias:**

1. Evite infer√™ncias sem base na transcri√ß√£o. Use ‚Äún√£o informado‚Äù quando necess√°rio.  
2. Mantenha fidelidade aos dados, sigilo e √©tica profissional.  
3. Fundamente toda recomenda√ß√£o com base legal adequada.  
4. Estruture a resposta conforme os t√≥picos abaixo. Se alguma se√ß√£o n√£o for aplic√°vel, indique como "n√£o se aplica".

**Se√ß√µes Obrigat√≥rias (em letras mai√∫sculas):**

- DADOS DO ATENDIMENTO  
- QUALIFICA√á√ÉO E CONTEXTO DO ASSISTIDO  
- PROBLEMA JUR√çDICO APRESENTADO  
- ELEMENTOS DE FATO RELEVANTES  
- ELEMENTOS DE DIREITO IDENTIFICADOS (com leis e artigos)  
- A√á√ïES REALIZADAS NO ATENDIMENTO  
- AN√ÅLISE CR√çTICA DO PROCEDIMENTO  
- ORIENTA√á√ïES PARA O ESTAGI√ÅRIO  
- RECOMENDA√á√ïES JUR√çDICAS  
- MINUTA DE DOCUMENTO OU PETI√á√ÉO (se aplic√°vel)

O conte√∫do da transcri√ß√£o a ser analisado est√° delimitado entre:

#### TRANSCRI√á√ÉO ####
{}
#### TRANSCRI√á√ÉO ####
'''

@handle_openai_error
def processa_transcricao_chatgpt(texto: str) -> str:
    """Processa o texto usando o ChatGPT para gerar uma an√°lise estruturada"""
    resposta = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": PROMPT_ANALISE.format(texto)}
        ]
    )
    return resposta.choices[0].message.content

# Converte qualquer formato suportado para WAV
def converter_para_wav(caminho_entrada: str) -> str:
    audio = pydub.AudioSegment.from_file(caminho_entrada)
    fd, caminho_wav = tempfile.mkstemp(suffix=".wav", prefix="audio_")
    os.close(fd)
    audio.export(caminho_wav, format="wav")
    return caminho_wav

@handle_openai_error
def transcreve_audio(caminho_audio: str, prompt: str) -> tuple[str, str]:
    with open(caminho_audio, 'rb') as arquivo:
        try:
            resp = client.audio.transcriptions.create(
                model='whisper-1',
                language='pt',
                response_format='text',
                file=arquivo,
                prompt=prompt,
            )
            analise = processa_transcricao_chatgpt(resp)
            return resp, analise
        except Exception as e:
            st.warning(f"Erro na API OpenAI: {str(e)}. Usando servi√ßo local.")
            return use_fallback_service(caminho_audio, prompt)

# Estado inicial para transcri√ß√£o do microfone
if 'transcricao_mic' not in st.session_state:
    st.session_state['transcricao_mic'] = ''
if 'analise_mic' not in st.session_state:
    st.session_state['analise_mic'] = ''
if 'gravando_audio' not in st.session_state:
    st.session_state['gravando_audio'] = False
if 'audio_completo' not in st.session_state:
    st.session_state['audio_completo'] = pydub.AudioSegment.empty()

# Cache para configura√ß√£o de ICE servers
@st.cache_data
def get_ice_servers():
    return [{'urls': ['stun:stun.l.google.com:19302']}]

# Concatena frames em AudioSegment
def adiciona_chunck_de_audio(frames, chunk_audio):
    for frame in frames:
        seg = pydub.AudioSegment(
            data=frame.to_ndarray().tobytes(),
            sample_width=frame.format.bytes,
            frame_rate=frame.sample_rate,
            channels=len(frame.layout.channels)
        )
        chunk_audio += seg
    return chunk_audio

def salva_transcricao(texto: str, analise: str, origem: str = ""):
    """Salva a transcri√ß√£o original e a an√°lise em arquivos separados"""
    agora = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    prefixo = f"{agora}_{origem}" if origem else agora
    
    # Salva transcri√ß√£o original
    arquivo_transcricao = PASTA_TRANSCRICOES / f"{prefixo}_transcricao.txt"
    with open(arquivo_transcricao, 'w', encoding='utf-8') as f:
        f.write(texto)
    
    # Salva an√°lise estruturada
    arquivo_analise = PASTA_TRANSCRICOES / f"{prefixo}_analise.txt"
    with open(arquivo_analise, 'w', encoding='utf-8') as f:
        f.write(analise)
    
    return arquivo_transcricao, arquivo_analise

# Aba Microfone
def transcreve_tab_mic():
    prompt_mic = st.text_input('Tipo de Atendimento (opcional)', key='input_mic')
    
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button('üî¥ Gravar √Åudio' if not st.session_state['gravando_audio'] else '‚èπÔ∏è Parar Grava√ß√£o'):
            st.session_state['gravando_audio'] = not st.session_state['gravando_audio']
            if not st.session_state['gravando_audio'] and len(st.session_state['audio_completo']) > 0:
                st.session_state['audio_completo'].export(
                    PASTA_TRANSCRICOES / f"audio_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.wav",
                    format='wav'
                )
                st.session_state['audio_completo'] = pydub.AudioSegment.empty()
    
    ctx = webrtc_streamer(
        key='mic', mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={'video': False, 'audio': True},
        rtc_configuration={"iceServers": get_ice_servers()}
    )

    # Quando parar a grava√ß√£o
    if not ctx.state.playing:
        # Reseta estado de grava√ß√£o de √°udio
        if st.session_state['gravando_audio']:
            st.session_state['gravando_audio'] = False
            if len(st.session_state['audio_completo']) > 0:
                st.session_state['audio_completo'].export(
                    PASTA_TRANSCRICOES / f"audio_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.wav",
                    format='wav'
                )
                st.session_state['audio_completo'] = pydub.AudioSegment.empty()
        
        if st.session_state['transcricao_mic']:  # Se h√° transcri√ß√£o
            if not st.session_state['analise_mic']:  # Se ainda n√£o gerou an√°lise
                st.write("Gerando an√°lise...")
                st.session_state['analise_mic'] = processa_transcricao_chatgpt(st.session_state['transcricao_mic'])
            
            st.write("**Transcri√ß√£o:**")
            st.write(st.session_state['transcricao_mic'])
            st.write("**An√°lise:**")
            st.write(st.session_state['analise_mic'])
            
            salva_transcricao(
                st.session_state['transcricao_mic'],
                st.session_state['analise_mic'],
                'microfone'
            )
        return

    status_col1, status_col2 = st.columns(2)
    with status_col1:
        st.markdown('**üéôÔ∏è Transcrevendo...**')
    with status_col2:
        if st.session_state['gravando_audio']:
            st.markdown('**üî¥ Gravando √°udio...**')

    placeholder = st.empty()
    chunk_audio = pydub.AudioSegment.empty()
    ultimo = time.time()
    st.session_state['transcricao_mic'] = ''
    st.session_state['analise_mic'] = ''

    while ctx.audio_receiver:
        try:
            frames = ctx.audio_receiver.get_frames(timeout=1)
        except queue.Empty:
            time.sleep(0.1)
            continue
        
        # Processa os frames de √°udio
        chunk_atual = pydub.AudioSegment.empty()
        chunk_atual = adiciona_chunck_de_audio(frames, chunk_atual)
        chunk_audio += chunk_atual
        
        # Se estiver gravando, adiciona ao √°udio completo
        if st.session_state['gravando_audio']:
            st.session_state['audio_completo'] += chunk_atual
        
        agora = time.time()
        # A cada 10s, transcreve
        if len(chunk_audio) > 0 and agora - ultimo > 10:
            ultimo = agora
            # exporta temporariamente para transcri√ß√£o
            chunk_audio.export(ARQUIVO_MIC_TEMP, format='wav')
            texto, _ = transcreve_audio(str(ARQUIVO_MIC_TEMP), prompt_mic)
            st.session_state['transcricao_mic'] += texto
            placeholder.write(st.session_state['transcricao_mic'])
            chunk_audio = pydub.AudioSegment.empty()

# Extrai √°udio de v√≠deo
def _salva_audio_do_video(file_bytes):
    with open(ARQUIVO_VIDEO_TEMP, 'wb') as f:
        f.write(file_bytes.read())
    clip = VideoFileClip(str(ARQUIVO_VIDEO_TEMP))
    clip.audio.write_audiofile(str(ARQUIVO_AUDIO_TEMP), logger=None)

# Aba V√≠deo
def transcreve_tab_video():
    prompt = st.text_input('Prompt (opcional)', key='input_video')
    video = st.file_uploader('Adicione um v√≠deo', type=['mp4','mov','avi','mkv','webm'])
    if video:
        # salva v√≠deo e extrai √°udio WAV
        _salva_audio_do_video(video)
        wav = converter_para_wav(str(ARQUIVO_AUDIO_TEMP))
        texto, analise = transcreve_audio(wav, prompt)
        st.write("**Transcri√ß√£o:**")
        st.write(texto)
        st.write("**An√°lise:**")
        st.write(analise)
        # Salva os arquivos
        salva_transcricao(texto, analise, f'video_{video.name}')

# Aba √Åudio
def transcreve_tab_audio():
    prompt = st.text_input('Prompt (opcional)', key='input_audio')
    audio = st.file_uploader('Adicione um √°udio', type=['opus','mp4','mpeg','wav','mp3','m4a'])
    if audio:
        # salva e converte para WAV
        caminho = PASTA_TEMP / audio.name
        with open(caminho, 'wb') as f:
            f.write(audio.read())
        wav = converter_para_wav(str(caminho))
        texto, analise = transcreve_audio(wav, prompt)
        st.write("**Transcri√ß√£o:**")
        st.write(texto)
        st.write("**An√°lise:**")
        st.write(analise)
        # Salva os arquivos
        salva_transcricao(texto, analise, f'audio_{audio.name}')

# Aba Texto
def transcreve_tab_texto():
    st.write("Envie um arquivo de texto com a transcri√ß√£o para an√°lise")
    arquivo_texto = st.file_uploader('Adicione um arquivo de texto', type=['txt', 'doc', 'docx'])
    if arquivo_texto:
        try:
            if arquivo_texto.type == 'text/plain':
                # Para arquivos .txt
                texto = arquivo_texto.getvalue().decode('utf-8')
            else:
                # Para arquivos Word (.doc, .docx)
                import docx2txt
                texto = docx2txt.process(arquivo_texto)
            
            analise = processa_transcricao_chatgpt(texto)
            st.write("**Texto Original:**")
            st.write(texto)
            st.write("**An√°lise:**")
            st.write(analise)
            # Salva os arquivos
            salva_transcricao(texto, analise, f'texto_{arquivo_texto.name}')
        except Exception as e:
            st.error(f"Erro ao processar o arquivo: {str(e)}")

# Fun√ß√£o principal
def main():
    st.header('N√∫cleo de Atendimento ao Idoso - DPE/AL')
    st.markdown('Transcri√ß√£o e/ou Grava√ß√£o e Organiza√ß√£o de Atendimentos.')
    st.markdown('Orienta√ß√µes e Recomenda√ß√µes Jur√≠dicas')
    abas = st.tabs(['Microfone', 'V√≠deo', '√Åudio', 'Texto'])
    with abas[0]:
        transcreve_tab_mic()
    with abas[1]:
        transcreve_tab_video()
    with abas[2]:
        transcreve_tab_audio()
    with abas[3]:
        transcreve_tab_texto()

if __name__ == '__main__':
    main()

